{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a09c40a",
   "metadata": {},
   "source": [
    "### Lower the toxicity of the Generated Summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0..3.0 --quiet \\\n",
    "    trl==0.4.4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbf022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the Reinforcement Learning library directly from github.\n",
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7976dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528d00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, AutoModelForSequenceClassification, Trainer\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# Transformer Reinforcement Learning\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dccb0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/mobeenH20/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7614c314a55344c28fe606d91078e898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "model_name = 'google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# device_map=\"auto\" will switch b/w  CPU and GPU\n",
    "# it is essential to use the same tokenizer as of model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eff5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to preprocess the dataset, that includes finding dialogues of same length, place the instruction prompt for fine tuning\n",
    "\n",
    "def preprocess_dataset(dataset, min_input_length, max_input_length):\n",
    "    \n",
    "    # get the training data from dataset\n",
    "    dataset = dataset['train']\n",
    "    \n",
    "    # filter data for max and min input length\n",
    "    dataset = dataset.filter(lambda x: len(x['dialogue']) > min_input_length and \n",
    "                                       len(x['dialogue']) <= max_input_length , batched=False)\n",
    "\n",
    "    # wrapping the dataset in instruction prompt for training\n",
    "    def tokenize(sample):\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following dialogue:\n",
    "{sample['dialogue']}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "    \n",
    "    # tokenizing the dataset for training. \n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # test train split\n",
    "    dataset_split = dataset.train_test_split(test_size=0.3, shuffle=False, seed=42)\n",
    "    return dataset_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcff0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\mobeenH20\\.cache\\huggingface\\datasets\\knkarthick___csv\\knkarthick--dialogsum-cd36827d3490488d\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-aed840428c46ebbe.arrow\n",
      "Loading cached processed dataset at C:\\Users\\mobeenH20\\.cache\\huggingface\\datasets\\knkarthick___csv\\knkarthick--dialogsum-cd36827d3490488d\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-26a6061d3a56445f.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_dataset(dataset=original_dataset, min_input_length=200, max_input_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c5812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db76509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    total_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        total_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable Model Params: {trainable_model_params}\\ntotal Model Params: {total_model_params}\\npercentage of trainable Params: {100*(trainable_model_params/total_model_params):.3f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2baf5ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trainable parameters: trainable Model Params: 3538944\n",
      "total Model Params: 251116800\n",
      "percentage of trainable Params: 1.409%\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "peft_instruct_model = PeftModel.from_pretrained(\n",
    "                            original_model,\n",
    "                            \"./dialogue-summary-peft-training-save\",\n",
    "                            torch_dtype=torch.bfloat16,\n",
    "                            lora_config=lora_config,\n",
    "                            device_map=\"auto\",\n",
    "                            is_trainable=True            # if we need to prepare the model for further training we set to is_trainable=True. rn its  infering PEFT model\n",
    "                        )\n",
    "\n",
    "print(f\"number of trainable parameters: {trainable_model_parameters(peft_instruct_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89fd0a",
   "metadata": {},
   "source": [
    "### Fine-tune LLM with Reinforcement Learning (RL)\n",
    "\n",
    "We are preparing Proximal Policy Optimization (PPO) model passing instruct fine tuned PEFT model.\n",
    "Later PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303cb637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "trainable Model Params: 3539713\n",
      "total Model Params: 251117569\n",
      "percentage of trainable Params: 1.410%\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# this is for PPO traning\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_instruct_model,\n",
    "                                                              torch_dtype=torch.bfloat16,\n",
    "                                                              is_trainable=True)\n",
    "\n",
    "print(f\"PPO model parameters to be updated (ValueHead + 769 params):\\n{trainable_model_parameters(ppo_model)}\")\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8895d",
   "metadata": {},
   "source": [
    "#### Out of these 'trainable Model Params: 3539713' 768 came from ValueHead + Bias( it is important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c499567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to train: trainable Model Params: 0\n",
      "total Model Params: 251117569\n",
      "percentage of trainable Params: 0.000%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "when we go to training we will pass two model:\n",
    "    - reference model: that will not going to be train. That is the original instruct model.\n",
    "    - PPO model: that is fined tuned model\n",
    "    KL Divergents is used to evaluate whats the PPO model has generated and whats the original model (that we have trained in previous notebook now considered as a base model.) \n",
    "\n",
    "\"\"\" \n",
    "reference_model = create_reference_model(ppo_model)\n",
    "print(f\"Reference model parameters to train: {trainable_model_parameters(reference_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a3202",
   "metadata": {},
   "source": [
    "### Toxicity Model from facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee466c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e299f6",
   "metadata": {},
   "source": [
    "#### Now let see the toxicity model  in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c89cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999760091304779, 0.00023992054047994316]\n",
      "probablities:\n",
      "nothate:0.999760091304779\n",
      "hate:0.00023992054047994316\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"this is a good movie.\"\n",
    "toxic_text = \"hate the movie and it was pathetic and dump.\"\n",
    "labels = toxicity_model.config.id2label\n",
    "\n",
    "# tokenizing the input text\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "# print(f\"tokens: {toxicity_input_ids}\")\n",
    "\n",
    "# logits: from stackoverflow: logits refer to the element-wise inverse of the sigmoid function.\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "# print(f\"logits: {logits.tolist()[0]}\")\n",
    "\n",
    "# converting these logits into probabilities with sigmoid\n",
    "prob = logits.softmax(dim=1).tolist()[0]\n",
    "print(prob)\n",
    "print(f\"probablities:\\n{labels[0]}:{prob[0]}\\n{labels[1]}:{prob[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55758fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [4.447512149810791]\n"
     ]
    }
   ],
   "source": [
    "# get the logits for \"not hate\" - this is the reward\n",
    "not_hate_index = 0\n",
    "not_hate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f\"reward: {not_hate_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb742ae",
   "metadata": {},
   "source": [
    "### Hugging-face inference pipeline example for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac90a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#  \n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",\n",
    "                             model=\"facebook/roberta-hate-speech-dynabench-r4-target\",\n",
    "                             device=device)\n",
    "\n",
    "reward_logits_kwargs = {\n",
    "    \"top-k\": None, # Return all scores\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores\n",
    "    \"function_to_apply\": \"softmax\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "# print(sentiment_analysis(non_toxic_text, **reward_logits_kwargs))\n",
    "# print(sentiment_analysis(non_toxic_text, **reward_probabilities_kwargs))\n",
    "\n",
    "# print(sentiment_analysis(toxic_text, **reward_logits_kwargs))\n",
    "# print(sentiment_analysis(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c3212",
   "metadata": {},
   "source": [
    "## Evaluate toxicity before and after model training (between 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b6cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "evaluate_toxicity = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf89169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text: [0.0002399203076492995]\n",
      "Toxicity score for toxic text: [0.9104079604148865]\n"
     ]
    }
   ],
   "source": [
    "# Try to calculate toxicity for the same sentences\n",
    "\n",
    "toxicity_score = evaluate_toxicity.compute(predictions=[non_toxic_text])\n",
    "print(f\"Toxicity score for non-toxic text: {toxicity_score['toxicity']}\")\n",
    "\n",
    "toxicity_score = evaluate_toxicity.compute(predictions=[toxic_text])\n",
    "print(f\"Toxicity score for toxic text: {toxicity_score['toxicity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58978d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_toxicity(\n",
    "    tokenizer,\n",
    "    model,\n",
    "    dataset,\n",
    "    number_of_sample,\n",
    "    generation_config\n",
    "):\n",
    "    \n",
    "    max_new_token_size = 100\n",
    "    toxicity_list = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "        if i > number_of_sample:\n",
    "            break;\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids.to('cuda')\n",
    "        \n",
    "        response_token_ids = model.generate(input_ids=input_ids, generation_config=generation_config)\n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score = evaluate_toxicity.compute(predictions=[(input_text + \" \"+ generated_text)])\n",
    "        \n",
    "        toxicity_list.append(toxicity_score['toxicity'])\n",
    "\n",
    "    # to compute the mean toxicity score\n",
    "    mean = np.mean(toxicity_list)\n",
    "    std = np.std(toxicity_list)\n",
    "\n",
    "    return mean, std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75d609bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [07:45, 42.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean toxicity score - before fine-tuning: 0.0053667015745304525\n",
      "std toxicity score - before fine-tuning: 0.0061257415331252875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# toxicity before fine-tuning\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "generation_config = GenerationConfig(max_new_tokens=100,\n",
    "                                            top_k=0.0,\n",
    "                                            top_p=1.0,\n",
    "                                            do_sample=True)\n",
    "\n",
    "mean_before, std_before = eval_toxicity(tokenizer=tokenizer, \n",
    "                             model=reference_model, \n",
    "                             dataset=dataset['test'], \n",
    "                             number_of_sample=10,\n",
    "                             generation_config=generation_config)\n",
    "\n",
    "print(f\"mean toxicity score - before fine-tuning: {mean_before}\")\n",
    "print(f\"std toxicity score - before fine-tuning: {std_before}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300d82d",
   "metadata": {},
   "source": [
    "### The goal is to reduce the above Toxicity average by PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124b12f",
   "metadata": {},
   "source": [
    "### PPO Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876af2f",
   "metadata": {},
   "source": [
    "We will load both reference model (frozen version of the Model). This model will help to measure the KL-divergence. It is to keep an eye on new optimized model so it doesn't deviate too much from reference model (aka original LLM model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02faaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.41e-5\n",
    "max_ppo_epochs = 1\n",
    "mini_batch_size = 4\n",
    "batch_size = 16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name = model_name,\n",
    "    learning_rate = learning_rate,\n",
    "    ppo_epochs = max_ppo_epochs,\n",
    "    mini_batch_size = mini_batch_size,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=config,\n",
    "    model=ppo_model,\n",
    "    ref_model=reference_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset['train'],\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c7984",
   "metadata": {},
   "source": [
    "### Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dc0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "1it [00:21, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.0031920485198497772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:54, 28.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.015340277925133705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:17, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.09556488692760468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:45, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.11383634805679321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:19, 29.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.03181584179401398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:45, 28.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.03777473419904709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:09, 26.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.09216611087322235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:36, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.05683952569961548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:02, 26.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.10987281799316406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [04:30, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.07700534164905548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [04:51, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.05995362997055054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [05:14, 24.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.05630319193005562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [05:39, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.04205099865794182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [06:02, 24.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.058322709053754807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [06:32, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.13222619891166687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [06:58, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.0832252949476242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [07:34, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.017267966642975807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [08:16, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.07664337754249573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [09:07, 38.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.1580633819103241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [09:37, 36.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.27454155683517456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [10:02, 32.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.040126603096723557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [10:35, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.05221175402402878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [11:12, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.03201613947749138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [11:42, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.02819656953215599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [12:14, 32.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.026050660759210587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [12:37, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.01553802378475666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [13:01, 27.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.05788774788379669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [13:25, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.07625370472669601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [13:47, 25.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.057603321969509125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [14:08, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.053525637835264206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [14:30, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.07933111488819122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [14:56, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.0030426010489463806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [15:20, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.021420884877443314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [15:44, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.1401810348033905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [16:04, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.10003267228603363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [16:29, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.1908917874097824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [16:53, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.12680184841156006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [17:18, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.042717307806015015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [17:41, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.01658041961491108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [18:13, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.08181856572628021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [18:35, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.13016235828399658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [18:52, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.13820615410804749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [19:11, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.342926561832428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [19:36, 22.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.33672332763671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [20:00, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.16946840286254883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [20:24, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.14999714493751526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [20:42, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.3255085349082947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [21:03, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.14585565030574799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [21:27, 22.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: -0.05858045816421509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [21:49, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergent: 0.18184417486190796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# our objective is to minimize the KL-Divergent and maximize the mean return.\n",
    "\n",
    "\"\"\" \n",
    "We are basically combining the response and query (that is the prompt) and passing it to sentiment model for check hata/nothate\n",
    "From those sentiments, nothate logits are extracted and given to PPO trainer. That will minimize the loss function\n",
    "\"\"\"\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 500\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 20\n",
    "}\n",
    "max_ppo_steps = 50\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    \n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "    \n",
    "    prompt_tensors = batch['input_ids']\n",
    "    \n",
    "    # responses from PEFT model\n",
    "    summary_tensors = []\n",
    "    \n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "        \n",
    "        generation_kwargs['max_new_tokens'] = max_new_tokens\n",
    "        \n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    batch['response'] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "    \n",
    "    # reward output\n",
    "    query_response_pairs = [q+r for q,r in zip(batch[\"query\"], batch['response'])]\n",
    "    rewards = sentiment_analysis(query_response_pairs, **reward_kwargs)\n",
    "    \n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index]['score']) for reward in rewards]\n",
    "    \n",
    "    stats = ppo_trainer.step(prompt_tensors,  summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f\"KL Divergent: {stats['objective/kl']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c5556",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b9b6053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:15,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean toxicity score - after fine-tuning: 0.007172755193261599\n",
      "std toxicity score - after fine-tuning: 0.006276072876873347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# toxicity after fine-tuning\n",
    "mean_after, std_after = eval_toxicity(tokenizer=tokenizer, \n",
    "                             model=ppo_model, \n",
    "                             dataset=dataset['test'], \n",
    "                             number_of_sample=10,\n",
    "                             generation_config=generation_config)\n",
    "\n",
    "print(f\"mean toxicity score - after fine-tuning: {mean_after}\")\n",
    "print(f\"std toxicity score - after fine-tuning: {std_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1d3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of toxicity score after finr tuning:\n",
      "mean: -33.65%\n",
      "std: -2.45%\n"
     ]
    }
   ],
   "source": [
    "mean_improvement = (mean_before - mean_after) / mean_before\n",
    "std_improvement = (std_before - std_after) / std_before\n",
    "\n",
    "print(f'Percentage of toxicity score after finr tuning:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70fb7cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset['test'][0:batch_size]\n",
    "\n",
    "compare_results['query'] = df_batch['query']\n",
    "prompt_tensors = df_batch['input_ids']\n",
    "\n",
    "summary_tensors_reference = []\n",
    "summary_tensors_ppo = []\n",
    "\n",
    "# getting responses from PPO model\n",
    "for i in tqdm(range(batch_size)):\n",
    "    generated_text_length = output_length_sampler()\n",
    "    generation_kwargs['max_new_tokens'] = generated_text_length\n",
    "    \n",
    "    reference_summary = reference_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),**generation_kwargs).squeeze()[-generated_text_length:]\n",
    "    summary_tensors_reference.append(reference_summary)\n",
    "        \n",
    "    ppo_summary = ppo_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),**generation_kwargs).squeeze()[-generated_text_length:]\n",
    "    summary_tensors_ppo.append(ppo_summary)\n",
    "    \n",
    "# Decoding responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_reference[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors_ppo[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_analysis(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_analysis(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "270c97c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: I was told to come to you to get a chest X-ray. #Person2#: No problem. Just take your clothes off from the waist up and put the gown on, with the opening in the back. #Person1#: Then what should I do? #Person2#: You will stand over here up against this plate. #Person1#: Should I just stand naturally? #Person2#: You will raise your arms up shoulder high. #Person1#: Is this all right? #Person2#: Yes, you are doing great. #Person1#: Where will you be...</td>\n",
       "      <td>&lt;pad&gt; Location: Shrunk: Up head height: 28 cm per square inch = 14%&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Major Kevin Raindrop's chest X-ray took 10 minutes.&lt;/s&gt;</td>\n",
       "      <td>2.105177</td>\n",
       "      <td>2.969007</td>\n",
       "      <td>0.863830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: how long will it take us to drive to London? #Person2#: I think it's a distance of 180 kilometers from here to London, so it should be a two-hour drive on the motorway. #Person1#: that's unless there is a traffic jam. It could take three hours. #Person2#: you're right. We will be able to travel at high speeds at the beginning and end of the journey, because we will be in built-up areas. #Person1#: so, shall we allow three hours to cover the distan...</td>\n",
       "      <td>&lt;pad&gt; They both thought it would take them two-hour drive on the motorway to London. Now that they are planning to drive that distance would take them only 2:2. They came a mile long, 1,5m long and over five meters long.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; In 180 kilometers from port of London to London, they need 2 and 1/3 hours to drive.&lt;/s&gt;</td>\n",
       "      <td>2.700622</td>\n",
       "      <td>3.073411</td>\n",
       "      <td>0.372789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Reception desk, may I help you? #Person2#: Yes, this is Smith Brown, from room 1016. The last room on the east side of the hotel. #Person1#: Yes. Can I do something for you? #Person2#: You certainly can, I can't get to sleep. The people in the next room, room 1014 are making too much noise. They're probably having a birthday party. All the cheering and laughing are driving me crazy. #Person1#: I see I'll give them a call. #Person2#: I wish you wou...</td>\n",
       "      <td>&lt;pad&gt; Smith Brown is feeling disruptive after turning a noisy room inside the hotel into a room for a birthday party.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Smith Brown has a birthday party in room 1014 in room 1014.&lt;/s&gt;</td>\n",
       "      <td>2.448939</td>\n",
       "      <td>2.703289</td>\n",
       "      <td>0.254350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: May I help you? #Person2#: Yes. I would like to cash my travelers'check. Here you are. #Person1#: Sure. How do you like your money? #Person2#: In tens and twenties, please. #Person1#: No problem. Here you are. #Person2#: Thanks a lot. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The money is in tens to twenties.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1 will cash the check in the tens and twenties, thanks to #Person2#.&lt;/s&gt;</td>\n",
       "      <td>2.212248</td>\n",
       "      <td>2.371209</td>\n",
       "      <td>0.158961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Excuse me, but I'm looking for a gift for my friend. #Person2#: Is it a Chinese New Year's gift or a birthday gift? #Person1#: Well, it's a wedding gift. #Person2#: Oh, I see. Let me guess... something sexy for the new bride on her first night of marriage? #Person1#: Basically. But I have no idea what to get! She's American and kind of... #Person2#: Well-endowed? Don't worry. I have some bras with bigger cup sizes in the back. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; At the fantasy casino, you can save up to 100 bucks for a new bra.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Ask the person first about the new bra that they're looking for for the new bride of the new marriage.&lt;/s&gt;</td>\n",
       "      <td>1.261591</td>\n",
       "      <td>1.333938</td>\n",
       "      <td>0.072346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: You have worked in your present company for five years. #Person2#: Yes, I do. #Person1#: Why do you want to resign? #Person2#: As you know I serve as a secretary in my present company, I really want to look for a more challenging opportunity. #Person1#: What kind of work are you interested in? #Person2#: Just as you advertised in the newspaper. #Person1#: So you are interested in our company. #Person2#: Yes, what's more, your company is one of the...</td>\n",
       "      <td>&lt;pad&gt; Don't be afraid.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; After five years at the current company, Person1 wants to return to work.&lt;/s&gt;</td>\n",
       "      <td>2.414729</td>\n",
       "      <td>2.403966</td>\n",
       "      <td>-0.010763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Would you like your bags to be taken to your room? #Person2#: Yes, please. #Person1#: OK. I'll get the bellman to taka them up. Which bags are yours? #Person2#: My luggage is in the corner over there. They are the leather suitcase, the canvass holdall and the blue backpack. #Person1#: OK. #Person2#: Please be careful with the suitcase, it's very heavy. #Person1#: I'll let the bellboy know. Don't worry, he's very strong. #Person2#: And the holdall ...</td>\n",
       "      <td>&lt;pad&gt; There are mounting doors in the corner of the room from the other rooms.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The leather suitcase, the canvass holdall and the blue backpack are checked into the room where they are located.&lt;/s&gt;</td>\n",
       "      <td>2.357016</td>\n",
       "      <td>2.345670</td>\n",
       "      <td>-0.011346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: I hate to say goodbye, but it's late. #Person2#: Can't you stay for a little bit longer, it's only 8. #Person1#: I wish I could. But I'm afraid I can't. I've got some serious studying to do. I have to go. #Person2#: OK. See you on Today. #Person1#: See you on Moday. Have a great weekend. #Person2#: You too. Thanks for dropping in. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Even though it's late, there are two members that are still here.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Person1 has classmates that want to see a book?&lt;/s&gt;</td>\n",
       "      <td>3.609639</td>\n",
       "      <td>3.465418</td>\n",
       "      <td>-0.144221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: How's it going? #Person2#: I'm great. Thanks. #Person1#: What do you need? #Person2#: I need to know if I have any fees to pay. #Person1#: Actually, you do owe some fees. #Person2#: How much do I owe? #Person1#: Your fees total $ 235. 13. #Person2#: That's crazy! #Person1#: You need to pay these fees soon. #Person2#: Can I do that right now? #Person1#: Will you be paying with cash or check? #Person2#: I think I'll be paying with cash. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1 has requested #Person2 if she has any fees to cover.#Person1: You owe $235. 3 13.#Person2: Thank you so much! Try remaining patient and looking forward to you going now!&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; With the help of #1 personally, Person2 will get the bills done on 6/21 hr to recoup their revenues.&lt;/s&gt;</td>\n",
       "      <td>2.396725</td>\n",
       "      <td>2.203291</td>\n",
       "      <td>-0.193434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Why are you so dressed up? #Person2#: I am on my way out to the celebration party of my company and I have to meet some important customers there. How do I look? Is my make up OK? #Person1#: You look great. Your makeup is also perfect. #Person2#: Do you think I should wear a different dress? #Person1#: No, the one you have all looks great, especially with your purple shoes and your hair like that. #Person2#: Thanks for saying so. Do you have any i...</td>\n",
       "      <td>&lt;pad&gt; Probably, Person1 is hunting for a new dress, but Person2 knows what ale person3 should look like.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; For the celebration party, Person2 is going to dress up.&lt;/s&gt;</td>\n",
       "      <td>2.146451</td>\n",
       "      <td>1.924492</td>\n",
       "      <td>-0.221959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Can you tell me a little bit about yourself? #Person2#: I am a graduate of a technical university and have been employed as a technician with Company or approximately 10 years. #Person1#: Please explain why you are interested in leaving your current position and please elaborate on your technical skills. #Person2#: I am looking for a growth opportunity, which I feel is not available at my current employer. In terms of skills, I am Microsoft certif...</td>\n",
       "      <td>&lt;pad&gt; Want to move?&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; To understand why a person has been considering leaving their current job, use #Person1's Linework Qualifications From the bottom and you will work more supported, productively than @Person2 does. Werd: If your boss% uses those factual statements, the interviewer wants to help you with your application for that position.&lt;/s&gt;</td>\n",
       "      <td>2.589972</td>\n",
       "      <td>2.299335</td>\n",
       "      <td>-0.290636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: What are your weekend arrangements? #Person2#: There're many things I can do on weekends. #Person1#: What sort of things are you interested in? #Person2#: I'm keen on talking short trips to nearby scenic spots. More often than not, I go with some of my friends. By the way, what are your favorites? #Person1#: I love swimming and cycling. On Sunday morning I have swimming practice for an hour. In the afternoon, I just ride my bike around the city or...</td>\n",
       "      <td>&lt;pad&gt; In the weekend, Person1 proposes short trips to nearby scenic spots. On Sunday morning Person1 practiced swimming for an hour and is then on unicycle for two hours. Person2 prefers to do dance for an hour when relaxing.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; In person, it's fun to kick back and relax. In person, it's hard to get bored.&lt;/s&gt;</td>\n",
       "      <td>3.203752</td>\n",
       "      <td>2.902707</td>\n",
       "      <td>-0.301044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Are you sure Lucy has it bad for you? If she does, she will certainly bend over backwards for you. But if she doesn't, it would be a job to change her. #Person2#: I don't know whether she has it bad for me, but she enjoys being with me. #Person1#: And do you really love her? #Person2#: I think I do. I don't think I can be happier with another girl. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Both people logically agree it's hard to get along with Lucy. People imply sacrifice is necessary for them, but dire consequences can occur through it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Discuss the different opinions.&lt;/s&gt;</td>\n",
       "      <td>1.377058</td>\n",
       "      <td>1.075659</td>\n",
       "      <td>-0.301399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: There is a new coffee shop opening up down the street. #Person2#: I hope that they have a good menu. Most coffee shops only have coffee and Danish. #Person1#: That's right. You don't drink coffee, do you? #Person2#: No, so it's usually boring to join my friends in the afternoon at a regular coffee shop. #Person1#: What kind of things would you like to see on the menu? #Person2#: Maybe a fruit salad and a few different hot sandwiches at least. #Per...</td>\n",
       "      <td>&lt;pad&gt; Coffee shops usually only serve coffee, but a new coffee shop is opening up down the street. Come and visit it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; People have an on-going meeting at a coffee shop at the corner of 32nd and 49th streets. They go there and meet some other customers.&lt;/s&gt;</td>\n",
       "      <td>3.432916</td>\n",
       "      <td>3.116082</td>\n",
       "      <td>-0.316833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Hoo, I'm getting tired, Jeanine, been a long day. #Person2#: I'm not quitting yet. You know my favourite slogan, don't you? #Person1#: Yeah, I know. Shop till you drop. #Person2#: Right! #Person1#: I'm getting a little short on cash. Let's just window shop a little. #Person2#: Ok. #Person1#: Hey, Jeanine, get a load of that. It's beautiful. #Person2#: Ahahah, and I thought you were tired. #Person1#: You know.. I have a weakness for long dresses. #...</td>\n",
       "      <td>&lt;pad&gt; Person1 - someone who comes morning after class - Wants to buy a dress to go to their friends, as they share her favourite favourite slogan. Mary can help her, as she also loves her long dresses.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Jeanine is going to window shop something.&lt;/s&gt;</td>\n",
       "      <td>2.168522</td>\n",
       "      <td>1.727545</td>\n",
       "      <td>-0.440977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Excuse me, miss. I don't think we need the MP4 any more. We would like to refund it. #Person2#: May I see your receipt? #Person1#: Here you are. #Person2#: I am sorry, sir. You bought it 2 weeks ago, and you can only refund it in one week. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The customer can't refund the MP4: they have already sent a receipt and they had to wait 7-8 days for it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; W def you is telling me your receipt.&lt;/s&gt;</td>\n",
       "      <td>2.545494</td>\n",
       "      <td>2.055667</td>\n",
       "      <td>-0.489826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Sorry. What was that you said? #Person2#: I'll meet you at the Gate round about seven. #Person1#: Where? #Person2#: At the Gate. #Person1#: When, did you say? #Person2#: Round about seven. #Person1#: Who's coming? #Person2#: Peter. Peter Brown, you know. Don't forget to bring the letter. #Person1#: Sorry. I didn't quite catch what you said. There's a lot of noise outside. #Person2#: I told you not to forget to bring the letter. #Person1#: Loretta?...</td>\n",
       "      <td>&lt;pad&gt; Peter, Peter, Peter Brown and Loretta will ask Peter to bring the letter when they return to the meeting at the Gate at seven.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; People are driving, there's a lot of noise.&lt;/s&gt;</td>\n",
       "      <td>2.707506</td>\n",
       "      <td>2.091468</td>\n",
       "      <td>-0.616038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: To collect a data for my report, I need to talk to someone who knows that small city very well. I was told that you lived there for quite a long time. #Person2#: Oh, I wish I could help, but I was only a child then. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Person1: I need to talk to someone who knows that small city very well.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Someone with a lot of history can be a good data collector.&lt;/s&gt;</td>\n",
       "      <td>3.532832</td>\n",
       "      <td>2.886255</td>\n",
       "      <td>-0.646578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Do you like music? #Person2#: Well, it depends. #Person1#: Do you think the music is well-matched? #Person2#: No, I think the music is too fast. #Person1#: How about the words of the song? #Person2#: It sounds nice. #Person1#: I like it. Naturally it can arouse your feelings. #Person2#: Yes, I think so. It's very emotional. #Person1#: Of course, and I also like the rhythms. #Person2#: Full of energy and hope. #Person1#: Really. It's worth listenin...</td>\n",
       "      <td>&lt;pad&gt; During the interview, formal criteria were dealt to the crafting of the song, and the Acclaim Award.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Person 1: Like the music, person 2: Don't listen to it.&lt;/s&gt;</td>\n",
       "      <td>3.004433</td>\n",
       "      <td>2.224320</td>\n",
       "      <td>-0.780113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following dialogue: #Person1#: Wake up sleepyhead. The sun is beginning to shine. What a lovely summer day! #Person2#: Yeah, clearly blue sky. But it is a bit too hot for me. I don't like heat and humidity. #Person1#: It's not that hot. It's cooler than yesterday. Let's go swimming! #Person2#: That's a thought. It's still early, and the beach isn't crowded at this time of the day. If we don't stay too long, we won't get sunburned. #Person1#: Yeah, sounds like fun. I can wear my...</td>\n",
       "      <td>&lt;pad&gt; A smart guy will put some advice on their specialist if one is too lazy.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The gay guy doesn't seem to care about his bikini, but it's refreshing to look casual.&lt;/s&gt;</td>\n",
       "      <td>3.129426</td>\n",
       "      <td>0.169164</td>\n",
       "      <td>-2.960262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following dialogue: #Person1#: I was told to come to you to get a chest X-ray. #Person2#: No problem. Just take your clothes off from the waist up and put the gown on, with the opening in the back. #Person1#: Then what should I do? #Person2#: You will stand over here up against this plate. #Person1#: Should I just stand naturally? #Person2#: You will raise your arms up shoulder high. #Person1#: Is this all right? #Person2#: Yes, you are doing great. #Person1#: Where will you be...   \n",
       "1   Summarize the following dialogue: #Person1#: how long will it take us to drive to London? #Person2#: I think it's a distance of 180 kilometers from here to London, so it should be a two-hour drive on the motorway. #Person1#: that's unless there is a traffic jam. It could take three hours. #Person2#: you're right. We will be able to travel at high speeds at the beginning and end of the journey, because we will be in built-up areas. #Person1#: so, shall we allow three hours to cover the distan...   \n",
       "2   Summarize the following dialogue: #Person1#: Reception desk, may I help you? #Person2#: Yes, this is Smith Brown, from room 1016. The last room on the east side of the hotel. #Person1#: Yes. Can I do something for you? #Person2#: You certainly can, I can't get to sleep. The people in the next room, room 1014 are making too much noise. They're probably having a birthday party. All the cheering and laughing are driving me crazy. #Person1#: I see I'll give them a call. #Person2#: I wish you wou...   \n",
       "3                                                                                                                                                                                                                 Summarize the following dialogue: #Person1#: May I help you? #Person2#: Yes. I would like to cash my travelers'check. Here you are. #Person1#: Sure. How do you like your money? #Person2#: In tens and twenties, please. #Person1#: No problem. Here you are. #Person2#: Thanks a lot. Summary: </s>   \n",
       "4             Summarize the following dialogue: #Person1#: Excuse me, but I'm looking for a gift for my friend. #Person2#: Is it a Chinese New Year's gift or a birthday gift? #Person1#: Well, it's a wedding gift. #Person2#: Oh, I see. Let me guess... something sexy for the new bride on her first night of marriage? #Person1#: Basically. But I have no idea what to get! She's American and kind of... #Person2#: Well-endowed? Don't worry. I have some bras with bigger cup sizes in the back. Summary: </s>   \n",
       "5   Summarize the following dialogue: #Person1#: You have worked in your present company for five years. #Person2#: Yes, I do. #Person1#: Why do you want to resign? #Person2#: As you know I serve as a secretary in my present company, I really want to look for a more challenging opportunity. #Person1#: What kind of work are you interested in? #Person2#: Just as you advertised in the newspaper. #Person1#: So you are interested in our company. #Person2#: Yes, what's more, your company is one of the...   \n",
       "6   Summarize the following dialogue: #Person1#: Would you like your bags to be taken to your room? #Person2#: Yes, please. #Person1#: OK. I'll get the bellman to taka them up. Which bags are yours? #Person2#: My luggage is in the corner over there. They are the leather suitcase, the canvass holdall and the blue backpack. #Person1#: OK. #Person2#: Please be careful with the suitcase, it's very heavy. #Person1#: I'll let the bellboy know. Don't worry, he's very strong. #Person2#: And the holdall ...   \n",
       "7                                                                                                               Summarize the following dialogue: #Person1#: I hate to say goodbye, but it's late. #Person2#: Can't you stay for a little bit longer, it's only 8. #Person1#: I wish I could. But I'm afraid I can't. I've got some serious studying to do. I have to go. #Person2#: OK. See you on Today. #Person1#: See you on Moday. Have a great weekend. #Person2#: You too. Thanks for dropping in. Summary: </s>   \n",
       "8     Summarize the following dialogue: #Person1#: How's it going? #Person2#: I'm great. Thanks. #Person1#: What do you need? #Person2#: I need to know if I have any fees to pay. #Person1#: Actually, you do owe some fees. #Person2#: How much do I owe? #Person1#: Your fees total $ 235. 13. #Person2#: That's crazy! #Person1#: You need to pay these fees soon. #Person2#: Can I do that right now? #Person1#: Will you be paying with cash or check? #Person2#: I think I'll be paying with cash. Summary: </s>   \n",
       "9   Summarize the following dialogue: #Person1#: Why are you so dressed up? #Person2#: I am on my way out to the celebration party of my company and I have to meet some important customers there. How do I look? Is my make up OK? #Person1#: You look great. Your makeup is also perfect. #Person2#: Do you think I should wear a different dress? #Person1#: No, the one you have all looks great, especially with your purple shoes and your hair like that. #Person2#: Thanks for saying so. Do you have any i...   \n",
       "10  Summarize the following dialogue: #Person1#: Can you tell me a little bit about yourself? #Person2#: I am a graduate of a technical university and have been employed as a technician with Company or approximately 10 years. #Person1#: Please explain why you are interested in leaving your current position and please elaborate on your technical skills. #Person2#: I am looking for a growth opportunity, which I feel is not available at my current employer. In terms of skills, I am Microsoft certif...   \n",
       "11  Summarize the following dialogue: #Person1#: What are your weekend arrangements? #Person2#: There're many things I can do on weekends. #Person1#: What sort of things are you interested in? #Person2#: I'm keen on talking short trips to nearby scenic spots. More often than not, I go with some of my friends. By the way, what are your favorites? #Person1#: I love swimming and cycling. On Sunday morning I have swimming practice for an hour. In the afternoon, I just ride my bike around the city or...   \n",
       "12                                                                                            Summarize the following dialogue: #Person1#: Are you sure Lucy has it bad for you? If she does, she will certainly bend over backwards for you. But if she doesn't, it would be a job to change her. #Person2#: I don't know whether she has it bad for me, but she enjoys being with me. #Person1#: And do you really love her? #Person2#: I think I do. I don't think I can be happier with another girl. Summary: </s>   \n",
       "13  Summarize the following dialogue: #Person1#: There is a new coffee shop opening up down the street. #Person2#: I hope that they have a good menu. Most coffee shops only have coffee and Danish. #Person1#: That's right. You don't drink coffee, do you? #Person2#: No, so it's usually boring to join my friends in the afternoon at a regular coffee shop. #Person1#: What kind of things would you like to see on the menu? #Person2#: Maybe a fruit salad and a few different hot sandwiches at least. #Per...   \n",
       "14  Summarize the following dialogue: #Person1#: Hoo, I'm getting tired, Jeanine, been a long day. #Person2#: I'm not quitting yet. You know my favourite slogan, don't you? #Person1#: Yeah, I know. Shop till you drop. #Person2#: Right! #Person1#: I'm getting a little short on cash. Let's just window shop a little. #Person2#: Ok. #Person1#: Hey, Jeanine, get a load of that. It's beautiful. #Person2#: Ahahah, and I thought you were tired. #Person1#: You know.. I have a weakness for long dresses. #...   \n",
       "15                                                                                                                                                                                                           Summarize the following dialogue: #Person1#: Excuse me, miss. I don't think we need the MP4 any more. We would like to refund it. #Person2#: May I see your receipt? #Person1#: Here you are. #Person2#: I am sorry, sir. You bought it 2 weeks ago, and you can only refund it in one week. Summary: </s>   \n",
       "16  Summarize the following dialogue: #Person1#: Sorry. What was that you said? #Person2#: I'll meet you at the Gate round about seven. #Person1#: Where? #Person2#: At the Gate. #Person1#: When, did you say? #Person2#: Round about seven. #Person1#: Who's coming? #Person2#: Peter. Peter Brown, you know. Don't forget to bring the letter. #Person1#: Sorry. I didn't quite catch what you said. There's a lot of noise outside. #Person2#: I told you not to forget to bring the letter. #Person1#: Loretta?...   \n",
       "17                                                                                                                                                                                                                                   Summarize the following dialogue: #Person1#: To collect a data for my report, I need to talk to someone who knows that small city very well. I was told that you lived there for quite a long time. #Person2#: Oh, I wish I could help, but I was only a child then. Summary: </s>   \n",
       "18  Summarize the following dialogue: #Person1#: Do you like music? #Person2#: Well, it depends. #Person1#: Do you think the music is well-matched? #Person2#: No, I think the music is too fast. #Person1#: How about the words of the song? #Person2#: It sounds nice. #Person1#: I like it. Naturally it can arouse your feelings. #Person2#: Yes, I think so. It's very emotional. #Person1#: Of course, and I also like the rhythms. #Person2#: Full of energy and hope. #Person1#: Really. It's worth listenin...   \n",
       "19  Summarize the following dialogue: #Person1#: Wake up sleepyhead. The sun is beginning to shine. What a lovely summer day! #Person2#: Yeah, clearly blue sky. But it is a bit too hot for me. I don't like heat and humidity. #Person1#: It's not that hot. It's cooler than yesterday. Let's go swimming! #Person2#: That's a thought. It's still early, and the beach isn't crowded at this time of the day. If we don't stay too long, we won't get sunburned. #Person1#: Yeah, sounds like fun. I can wear my...   \n",
       "\n",
       "                                                                                                                                                                                                                          response_before  \\\n",
       "0                                                                                                                                                                 <pad> Location: Shrunk: Up head height: 28 cm per square inch = 14%</s>   \n",
       "1        <pad> They both thought it would take them two-hour drive on the motorway to London. Now that they are planning to drive that distance would take them only 2:2. They came a mile long, 1,5m long and over five meters long.</s>   \n",
       "2                                                                                                               <pad> Smith Brown is feeling disruptive after turning a noisy room inside the hotel into a room for a birthday party.</s>   \n",
       "3                                                                                                                                                                                             <pad> The money is in tens to twenties.</s>   \n",
       "4                                                                                                                                                            <pad> At the fantasy casino, you can save up to 100 bucks for a new bra.</s>   \n",
       "5                                                                                                                                                                                                              <pad> Don't be afraid.</s>   \n",
       "6                                                                                                                                                      <pad> There are mounting doors in the corner of the room from the other rooms.</s>   \n",
       "7                                                                                                                                                             <pad> Even though it's late, there are two members that are still here.</s>   \n",
       "8                                            <pad> #Person1 has requested #Person2 if she has any fees to cover.#Person1: You owe $235. 3 13.#Person2: Thank you so much! Try remaining patient and looking forward to you going now!</s>   \n",
       "9                                                                                                                            <pad> Probably, Person1 is hunting for a new dress, but Person2 knows what ale person3 should look like.</s>   \n",
       "10                                                                                                                                                                                                                <pad> Want to move?</s>   \n",
       "11  <pad> In the weekend, Person1 proposes short trips to nearby scenic spots. On Sunday morning Person1 practiced swimming for an hour and is then on unicycle for two hours. Person2 prefers to do dance for an hour when relaxing.</s>   \n",
       "12                                                                      <pad> Both people logically agree it's hard to get along with Lucy. People imply sacrifice is necessary for them, but dire consequences can occur through it.</s>   \n",
       "13                                                                                                              <pad> Coffee shops usually only serve coffee, but a new coffee shop is opening up down the street. Come and visit it.</s>   \n",
       "14                          <pad> Person1 - someone who comes morning after class - Wants to buy a dress to go to their friends, as they share her favourite favourite slogan. Mary can help her, as she also loves her long dresses.</s>   \n",
       "15                                                                                                                    <pad> The customer can't refund the MP4: they have already sent a receipt and they had to wait 7-8 days for it.</s>   \n",
       "16                                                                                               <pad> Peter, Peter, Peter Brown and Loretta will ask Peter to bring the letter when they return to the meeting at the Gate at seven.</s>   \n",
       "17                                                                                                                                                      <pad> Person1: I need to talk to someone who knows that small city very well.</s>   \n",
       "18                                                                                                                         <pad> During the interview, formal criteria were dealt to the crafting of the song, and the Acclaim Award.</s>   \n",
       "19                                                                                                                                                     <pad> A smart guy will put some advice on their specialist if one is too lazy.</s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                  response_after  \\\n",
       "0                                                                                                                                                                                                                                                                                  <pad> Major Kevin Raindrop's chest X-ray took 10 minutes.</s>   \n",
       "1                                                                                                                                                                                                                                                 <pad> In 180 kilometers from port of London to London, they need 2 and 1/3 hours to drive.</s>   \n",
       "2                                                                                                                                                                                                                                                                          <pad> Smith Brown has a birthday party in room 1014 in room 1014.</s>   \n",
       "3                                                                                                                                                                                                                                                          <pad> #Person1 will cash the check in the tens and twenties, thanks to #Person2#.</s>   \n",
       "4                                                                                                                                                                                                                               <pad> Ask the person first about the new bra that they're looking for for the new bride of the new marriage.</s>   \n",
       "5                                                                                                                                                                                                                                                            <pad> After five years at the current company, Person1 wants to return to work.</s>   \n",
       "6                                                                                                                                                                                                                    <pad> The leather suitcase, the canvass holdall and the blue backpack are checked into the room where they are located.</s>   \n",
       "7                                                                                                                                                                                                                                                                                      <pad> Person1 has classmates that want to see a book?</s>   \n",
       "8                                                                                                                                                                                                                                 <pad> With the help of #1 personally, Person2 will get the bills done on 6/21 hr to recoup their revenues.</s>   \n",
       "9                                                                                                                                                                                                                                                                             <pad> For the celebration party, Person2 is going to dress up.</s>   \n",
       "10  <pad> To understand why a person has been considering leaving their current job, use #Person1's Linework Qualifications From the bottom and you will work more supported, productively than @Person2 does. Werd: If your boss% uses those factual statements, the interviewer wants to help you with your application for that position.</s>   \n",
       "11                                                                                                                                                                                                                                                      <pad> In person, it's fun to kick back and relax. In person, it's hard to get bored.</s>   \n",
       "12                                                                                                                                                                                                                                                                                                     <pad> Discuss the different opinions.</s>   \n",
       "13                                                                                                                                                                                               <pad> People have an on-going meeting at a coffee shop at the corner of 32nd and 49th streets. They go there and meet some other customers.</s>   \n",
       "14                                                                                                                                                                                                                                                                                          <pad> Jeanine is going to window shop something.</s>   \n",
       "15                                                                                                                                                                                                                                                                                               <pad> W def you is telling me your receipt.</s>   \n",
       "16                                                                                                                                                                                                                                                                                         <pad> People are driving, there's a lot of noise.</s>   \n",
       "17                                                                                                                                                                                                                                                                         <pad> Someone with a lot of history can be a good data collector.</s>   \n",
       "18                                                                                                                                                                                                                                                                             <pad> Person 1: Like the music, person 2: Don't listen to it.</s>   \n",
       "19                                                                                                                                                                                                                                              <pad> The gay guy doesn't seem to care about his bikini, but it's refreshing to look casual.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        2.105177      2.969007     0.863830  \n",
       "1        2.700622      3.073411     0.372789  \n",
       "2        2.448939      2.703289     0.254350  \n",
       "3        2.212248      2.371209     0.158961  \n",
       "4        1.261591      1.333938     0.072346  \n",
       "5        2.414729      2.403966    -0.010763  \n",
       "6        2.357016      2.345670    -0.011346  \n",
       "7        3.609639      3.465418    -0.144221  \n",
       "8        2.396725      2.203291    -0.193434  \n",
       "9        2.146451      1.924492    -0.221959  \n",
       "10       2.589972      2.299335    -0.290636  \n",
       "11       3.203752      2.902707    -0.301044  \n",
       "12       1.377058      1.075659    -0.301399  \n",
       "13       3.432916      3.116082    -0.316833  \n",
       "14       2.168522      1.727545    -0.440977  \n",
       "15       2.545494      2.055667    -0.489826  \n",
       "16       2.707506      2.091468    -0.616038  \n",
       "17       3.532832      2.886255    -0.646578  \n",
       "18       3.004433      2.224320    -0.780113  \n",
       "19       3.129426      0.169164    -2.960262  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3bcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8f3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
